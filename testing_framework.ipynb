{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing_framework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1eTQQMou4g88EYXZePTS4YqKeF4qY0J1K",
      "authorship_tag": "ABX9TyPbqUN66LWzJPofTuGK6f0z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandraiyer/access_forums_eval/blob/main/testing_framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KSgOPNxnoZl"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from itertools import combinations"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiKlFa2un4X6"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/final.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87O6SXfhoAEn",
        "outputId": "6c55db95-2fed-4952-96b6-a76cb5d87fa0"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Thread', 'DateTime', 'Author', 'Post', 'ParentPosts', 'PostID',\n",
              "       'ThreadID', 'AuthorID', 'OriginID', 'DialogAct', 'ParentID_List'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_s_nT-VoBuQ"
      },
      "source": [
        "df = data[['Thread','ThreadID','PostID','DateTime','Author','Post','ParentID_List']]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "z_op2WSkoaUf",
        "outputId": "3b17c0df-9133-4d4e-8380-0f97ef3d3f3d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Thread</th>\n",
              "      <th>ThreadID</th>\n",
              "      <th>PostID</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>Author</th>\n",
              "      <th>Post</th>\n",
              "      <th>ParentID_List</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Testing the new Site!</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-11-30 11:59:19.544597</td>\n",
              "      <td>Tim Ford</td>\n",
              "      <td>Thank you very much for all those who worked o...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Netflix not accessible to blind people using a...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-11-30 12:05:11.019288</td>\n",
              "      <td>Tim Ford</td>\n",
              "      <td>Hi All,  For those out there who want to use N...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Testing the new Site!</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2015-11-30 12:06:01.976409</td>\n",
              "      <td>Walker, Michael E</td>\n",
              "      <td>Hi Tim, the group is working fine. I got your ...</td>\n",
              "      <td>[0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Testing the new Site!</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2015-11-30 12:12:07.800324</td>\n",
              "      <td>ken lawrence</td>\n",
              "      <td>Should the JDH mail be deleted?</td>\n",
              "      <td>[0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Netflix not accessible to blind people using a...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2015-11-30 12:14:27.873186</td>\n",
              "      <td>Greg Nickel</td>\n",
              "      <td>Will doâ€¦</td>\n",
              "      <td>[1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Thread  ...  ParentID_List\n",
              "0                              Testing the new Site!  ...             -1\n",
              "1  Netflix not accessible to blind people using a...  ...             -1\n",
              "2                              Testing the new Site!  ...            [0]\n",
              "3                              Testing the new Site!  ...            [0]\n",
              "4  Netflix not accessible to blind people using a...  ...            [1]\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjqY8pDKyCZJ"
      },
      "source": [
        "from itertools import chain\n",
        "from itertools import product\n",
        "from itertools import starmap\n",
        "from functools import partial\n",
        "import networkx as nx"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvU4f4YwG61-"
      },
      "source": [
        "def get_conversation_dag(tid):\n",
        "  temp = df[df['ThreadID']==tid]\n",
        "\n",
        "  threads = list(temp['Thread'])\n",
        "  postids = list(temp['PostID'])\n",
        "  posts = list(temp['Post'])\n",
        "  datetimes = list(temp['DateTime'])\n",
        "  authors = list(temp['Author'])\n",
        "  parentids = list(temp['ParentID_List'])\n",
        "\n",
        "  G = nx.DiGraph()\n",
        "  G.add_nodes_from(posts)\n",
        "\n",
        "  edges = []\n",
        "  for i in range(len(postids)):\n",
        "    parent = parentids[i]\n",
        "    child = postids[i]\n",
        "\n",
        "    if parent == \"-1\":\n",
        "      continue\n",
        "    else:\n",
        "      parent = int(parent[1:-1])\n",
        "    edges.append((parent,child))\n",
        "  G.add_edges_from(edges)\n",
        "  return G"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q78OSDuQpAB4"
      },
      "source": [
        "def get_subthreads(tid):\n",
        "  temp = df[df['ThreadID']==tid]\n",
        "\n",
        "  threads = list(temp['Thread'])\n",
        "  postids = list(temp['PostID'])\n",
        "  posts = list(temp['Post'])\n",
        "  datetimes = list(temp['DateTime'])\n",
        "  authors = list(temp['Author'])\n",
        "  parentids = list(temp['ParentID_List'])\n",
        "\n",
        "  G = nx.DiGraph()\n",
        "  G.add_nodes_from(posts)\n",
        "\n",
        "  edges = []\n",
        "  for i in range(len(postids)):\n",
        "    parent = parentids[i]\n",
        "    child = postids[i]\n",
        "\n",
        "    if parent == \"-1\":\n",
        "      continue\n",
        "    else:\n",
        "      parent = int(parent[1:-1])\n",
        "    edges.append((parent,child))\n",
        "  G.add_edges_from(edges)\n",
        "  chaini = chain.from_iterable\n",
        "  roots = (n for n,d in G.in_degree() if d==0)\n",
        "  leaves = (n for n,d in G.out_degree() if d==0)\n",
        "  all_paths = partial(nx.all_simple_paths, G)\n",
        "  ans = list(chaini(starmap(all_paths, product(roots, leaves))))\n",
        "  return(ans)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcoRgdChyewT"
      },
      "source": [
        "def get_list_subthreads(cluster_name,threadID):\n",
        "  conversations = []\n",
        "  for i, val in enumerate(get_subthreads(threadID)):\n",
        "    conversations.append(cluster_name+str(i)+\":\"+str(val)[1:-1].replace(',',''))\n",
        "  return conversations"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7auWny7jHMk",
        "outputId": "c2777929-7770-45a7-a45f-03339baaecbb"
      },
      "source": [
        "get_list_subthreads('C',4445)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['C0:21680 21681', 'C1:21680 21682', 'C2:21680 21683']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyTMWsK0DFV8"
      },
      "source": [
        "def read_clusters(filename):\n",
        "    # Read provided data\n",
        "    clusters = {}\n",
        "    cfile = \"\"\n",
        "    all_points = set()\n",
        "    for line in filename:\n",
        "        if ':' in line:\n",
        "            cfile = ':'.join(line.split(':')[:-1]).split('/')[-1]\n",
        "            line = line.split(\":\")[-1]\n",
        "        cluster = {int(v) for v in line.split()}\n",
        "        clusters.setdefault(cfile, []).append(cluster)\n",
        "        for v in cluster:\n",
        "            all_points.add(\"{}:{}\".format(cfile, v))\n",
        "    return clusters, all_points"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPldSHLuFzmM"
      },
      "source": [
        "def create_contingency_table(gold, auto):\n",
        "  table = []\n",
        "  names_gold = []\n",
        "  names_auto = []\n",
        "  for i, _ in gold.items():\n",
        "    names_gold.append(i)\n",
        "  for i, _ in auto.items():\n",
        "    names_auto.append(i)\n",
        "  for i, v1 in gold.items():\n",
        "    table_row = []\n",
        "    for j, v2 in auto.items():\n",
        "      table_row.append(len(v1.intersection(v2)))\n",
        "    table.append(table_row)\n",
        "  table = np.array(table)\n",
        "  sum_rows = np.sum(table, axis = 1)\n",
        "  sum_cols = np.sum(table, axis = 0)\n",
        "  return table, sum_rows, sum_cols, names_gold, names_auto"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr2ZshqoFr_j"
      },
      "source": [
        "def get_n(gold):\n",
        "  u = set([])\n",
        "  for _,v in gold.items():\n",
        "    u = u.union(set(v))\n",
        "  return(len(u))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A8nRpNZMuxF"
      },
      "source": [
        "def get_length_clustering(s):\n",
        "  list_len = []\n",
        "  for _,v in s.items():\n",
        "    list_len.append(len(v))\n",
        "  return(list_len)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRiDqXHAl1Q9"
      },
      "source": [
        "def get_points(gold):\n",
        "  u = set([])\n",
        "  for _,v in gold.items():\n",
        "    u = u.union(set(v))\n",
        "  return(u)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvdiSdDeF0DH"
      },
      "source": [
        "def get_vi(s1,s2):\n",
        "  c,c_rows,c_cols,g_name, a_name = create_contingency_table(s1,s2)\n",
        "  #print(c)\n",
        "  N = get_n(s1)\n",
        "  \n",
        "  H_uv = 0.0\n",
        "  I_uv = 0.0\n",
        "\n",
        "  X = get_length_clustering(s1)\n",
        "  Y = get_length_clustering(s2)\n",
        "  total = N\n",
        "  for i in range(len(c_rows)):\n",
        "    for j in range(len(c_cols)):\n",
        "      if c[i][j] != 0:\n",
        "        num = c[i][j]\n",
        "        A = c[i][j] / X[i]\n",
        "        B = c[i][j] / Y[j]\n",
        "        H_uv = H_uv - (num / total) * math.log(num / total, 2)\n",
        "        I_uv = I_uv + (num / total) * math.log(num * total / (X[i] * Y[j]), 2)\n",
        "      else:\n",
        "        continue\n",
        "  max_score = math.log(total, 2)\n",
        "  VI = H_uv - I_uv\n",
        "    \n",
        "  scaled_VI = VI / max_score\n",
        "  #print(sum_vi,math.log(total,2),scaled_vi,1-scaled_vi)\n",
        "  return round((1 - scaled_VI),3)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekGlj84Kruve"
      },
      "source": [
        "def get_one_to_one(s1,s2):\n",
        "  contingency,rows_sums,col_sums,gold_name,auto_name = create_contingency_table(s1,s2)\n",
        "  X = get_length_clustering(s1)\n",
        "  Y = get_length_clustering(s2)\n",
        "  N = get_n(s1)\n",
        "  B = nx.Graph()\n",
        "  left_nodes = []\n",
        "  for i in gold_name:\n",
        "    left_nodes.append('Left_'+str(i))\n",
        "  right_nodes = []\n",
        "  for i in auto_name:\n",
        "    right_nodes.append('Right_'+str(i))\n",
        "  B.add_nodes_from(left_nodes, bipartite=0)\n",
        "  B.add_nodes_from(right_nodes, bipartite=1)\n",
        "\n",
        "  for i in range(len(X)):\n",
        "    for j in range(len(Y)):\n",
        "      B.add_edge(left_nodes[i], right_nodes[j], weight = contingency[i][j])\n",
        "  \n",
        "  matches = nx.algorithms.matching.max_weight_matching(B)\n",
        "  one_one_ratio = 0.0\n",
        "  for u,v in matches:\n",
        "    one_one_ratio = one_one_ratio + (100.0 * B.get_edge_data(u,v)['weight']/N)\n",
        "  one_one_ratio = one_one_ratio\n",
        "  return(round(one_one_ratio,3))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC8_1d4a-M6K"
      },
      "source": [
        "def get_omega_score(s1,s2):\n",
        "  n = get_n(s1)\n",
        "  N = n*(n-1.0)/2.0\n",
        "  all_points = get_points(s1)\n",
        "  all_pairs = combinations(all_points,2)\n",
        "  s1_count = {}\n",
        "  s2_count = {}\n",
        "  for i,j in all_pairs:\n",
        "    for m,n in s1.items():\n",
        "      if i in n and j in n:\n",
        "        if (i,j) in s1_count:\n",
        "          s1_count[(i,j)] = s1_count.get((i,j)) + 1\n",
        "        else:\n",
        "          s1_count[(i,j)] = 1\n",
        "      else:\n",
        "        if (i,j) in s1_count:\n",
        "          s1_count[(i,j)] = s1_count.get((i,j)) + 0\n",
        "        else:\n",
        "          s1_count[(i,j)] = 0\n",
        "    for m,n in s2.items():\n",
        "      if i in n and j in n:\n",
        "        if (i,j) in s2_count:\n",
        "          s2_count[(i,j)] = s2_count.get((i,j)) + 1\n",
        "        else:\n",
        "          s2_count[(i,j)] = 1\n",
        "      else:\n",
        "        if (i,j) in s2_count:\n",
        "          s2_count[(i,j)] = s2_count.get((i,j)) + 0\n",
        "        else:\n",
        "          s2_count[(i,j)] = 0\n",
        "  #print(s1_count)\n",
        "  #print(s2_count)\n",
        "  count_s1_rev = {}\n",
        "  count_s2_rev = {}\n",
        "  for (i,j),k in s1_count.items():\n",
        "    if count_s1_rev.get((k),-1)!=-1:\n",
        "      count_s1_rev[k] = count_s1_rev.get(k).union(set([(i,j)]))\n",
        "    else:\n",
        "      count_s1_rev[k] = set([(i,j)])\n",
        "  for (i,j),k in s2_count.items():\n",
        "    if count_s2_rev.get((k),-1)!=-1:\n",
        "      count_s2_rev[k] = count_s2_rev.get(k).union(set([(i,j)]))\n",
        "    else:\n",
        "      count_s2_rev[k] = set([(i,j)])\n",
        "  #print(count_s1_rev)\n",
        "  #print(count_s2_rev)\n",
        "  i_max = max(list(count_s1_rev.keys()))\n",
        "  j_max = max(list(count_s2_rev.keys()))\n",
        "  min_ij = min(i_max,j_max)\n",
        "  #print(min_ij)\n",
        "  count_s1_s2_rev = {}\n",
        "  for i in range(0,min_ij+1):\n",
        "    inter = count_s1_rev.get(i,set([])).intersection(count_s2_rev.get(i,set([])))\n",
        "    count_s1_s2_rev[i] = inter\n",
        "  #print(count_s1_s2_rev)\n",
        "  U_sum = 0.0\n",
        "  for i in range(0,min_ij+1):\n",
        "    U_sum = U_sum + len(count_s1_s2_rev.get(i,set([])))\n",
        "  U_sum = U_sum / N\n",
        "  E_sum = 0.0\n",
        "  for i in range(0,min_ij+1):\n",
        "    E_sum = E_sum + (len(count_s1_rev.get(i,set([])))*len(count_s2_rev.get(i,set([]))))\n",
        "  E_sum = E_sum / (N * N)\n",
        "  \n",
        "  omega = (U_sum - E_sum)/(1.0- E_sum)\n",
        "  return(round(omega,3))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWVlG5JVJt8l"
      },
      "source": [
        "def create_shen_precision_table(s1, s2):\n",
        "  table = []\n",
        "\n",
        "  X = get_length_clustering(s1)\n",
        "  Y = get_length_clustering(s2)\n",
        "\n",
        "  a = 0\n",
        "  b = 0\n",
        "  for i, v1 in s1.items():\n",
        "    table_row = []\n",
        "    n_i = X[a]\n",
        "    b = 0\n",
        "    for j, v2 in s2.items():\n",
        "      n_j = Y[b]\n",
        "      table_row.append(len(v1.intersection(v2))/n_j)\n",
        "      b = b+1\n",
        "    table.append(table_row)\n",
        "    a=a+1\n",
        "  table = np.array(table)\n",
        "  \n",
        "  return table"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxs9EdkRJuSm"
      },
      "source": [
        "def create_shen_recall_table(s1, s2):\n",
        "  table = []\n",
        "  \n",
        "  X = get_length_clustering(s1)\n",
        "  Y = get_length_clustering(s2)\n",
        "\n",
        "  a = 0\n",
        "  b = 0\n",
        "  for i, v1 in s1.items():\n",
        "    table_row = []\n",
        "    n_i = X[a]\n",
        "    b = 0\n",
        "    for j, v2 in s2.items():\n",
        "      n_j = Y[b]\n",
        "      table_row.append(len(v1.intersection(v2))/n_i)\n",
        "      b = b+1\n",
        "    table.append(table_row)\n",
        "    a=a+1\n",
        "  table = np.array(table)\n",
        "  \n",
        "  return table"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45xR_bhSJuc2"
      },
      "source": [
        "def create_shen_F_table(s1, s2):\n",
        "  prec_table = create_shen_precision_table(s1,s2)\n",
        "  recall_table = create_shen_recall_table(s1,s2)\n",
        " \n",
        "  X = get_length_clustering(s1)\n",
        "  Y = get_length_clustering(s2)\n",
        "\n",
        "  a = 0\n",
        "  b = 0\n",
        "  max_f = []\n",
        "  for i, v1 in s1.items():\n",
        "    table_row = []\n",
        "    n_i = X[a]\n",
        "    b = 0\n",
        "    for j, v2 in s2.items():\n",
        "      n_j = Y[b]\n",
        "      f = (2 * prec_table[a][b] * recall_table[a][b])/(prec_table[a][b] + recall_table[a][b])\n",
        "      table_row.append(f)\n",
        "      b = b+1\n",
        "    max_f.append(max(table_row))\n",
        "    a=a+1\n",
        "\n",
        "  return max_f"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJo_NhkX5Kgd"
      },
      "source": [
        "def get_shen_f1(s1,s2):\n",
        "  max_f_table = create_shen_F_table(s1,s2)\n",
        "  sum_f = 0.0\n",
        "  n = get_n(s1)\n",
        "  X = get_length_clustering(s1)\n",
        "\n",
        "  for i in range(len(max_f_table)):\n",
        "    sum_f = sum_f + ( (X[i]/n) * max_f_table[i])\n",
        "  return(round(sum_f,3))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWrHAbJO-Rq2"
      },
      "source": [
        "def get_wang_f1(s1,s2):"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJwN2C5V9Ms8",
        "outputId": "4352bb38-65b1-464d-a4d9-1d11a8ec32cf"
      },
      "source": [
        "gold = {'C0':{1,2,3,4},'C1':{5,6}}\n",
        "auto = {'C0':{1,2,5,6},'C1':{3,4}}\n",
        "VI = get_vi(gold, auto)\n",
        "one_one = get_one_to_one(gold,auto)\n",
        "omega = get_omega_score(gold,auto)\n",
        "shen_f1 = get_shen_f1(gold,auto)\n",
        "\n",
        "print(VI, one_one, omega,shen_f1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.484 66.667 -0.071 0.667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsFtHM7u_t1v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}