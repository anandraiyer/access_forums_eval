{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing_framework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1eTQQMou4g88EYXZePTS4YqKeF4qY0J1K",
      "authorship_tag": "ABX9TyPl7wKbyO3JnnvkgTSUIhYx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandraiyer/access_forums_eval/blob/main/testing_framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KSgOPNxnoZl"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiKlFa2un4X6"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/final.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87O6SXfhoAEn",
        "outputId": "82b37063-4f95-4ab9-bc57-492948d75efa"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Thread', 'DateTime', 'Author', 'Post', 'ParentPosts', 'PostID',\n",
              "       'ThreadID', 'AuthorID', 'OriginID', 'DialogAct', 'ParentID_List'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_s_nT-VoBuQ"
      },
      "source": [
        "df = data[['Thread','ThreadID','PostID','DateTime','Author','Post','ParentID_List']]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "z_op2WSkoaUf",
        "outputId": "6a0535d5-9efa-488d-be29-c6642a6d0ec9"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Thread</th>\n",
              "      <th>ThreadID</th>\n",
              "      <th>PostID</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>Author</th>\n",
              "      <th>Post</th>\n",
              "      <th>ParentID_List</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Testing the new Site!</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-11-30 11:59:19.544597</td>\n",
              "      <td>Tim Ford</td>\n",
              "      <td>Thank you very much for all those who worked o...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Netflix not accessible to blind people using a...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-11-30 12:05:11.019288</td>\n",
              "      <td>Tim Ford</td>\n",
              "      <td>Hi All,  For those out there who want to use N...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Testing the new Site!</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2015-11-30 12:06:01.976409</td>\n",
              "      <td>Walker, Michael E</td>\n",
              "      <td>Hi Tim, the group is working fine. I got your ...</td>\n",
              "      <td>[0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Testing the new Site!</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2015-11-30 12:12:07.800324</td>\n",
              "      <td>ken lawrence</td>\n",
              "      <td>Should the JDH mail be deleted?</td>\n",
              "      <td>[0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Netflix not accessible to blind people using a...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2015-11-30 12:14:27.873186</td>\n",
              "      <td>Greg Nickel</td>\n",
              "      <td>Will do…</td>\n",
              "      <td>[1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Thread  ...  ParentID_List\n",
              "0                              Testing the new Site!  ...             -1\n",
              "1  Netflix not accessible to blind people using a...  ...             -1\n",
              "2                              Testing the new Site!  ...            [0]\n",
              "3                              Testing the new Site!  ...            [0]\n",
              "4  Netflix not accessible to blind people using a...  ...            [1]\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4m-DrW5Nj4H",
        "outputId": "c800cf06-73d9-42c7-e08d-024d53d901b9"
      },
      "source": [
        "for i in df[df['ThreadID']==34]['Post']:\n",
        "  print(i)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi guys, I am licensed for jaws 17 but had to down grade back to 16 due to an issue. When I read an email message with outlook express,  jaws says blank and I keep having to alt f 4 out of it. Have anyone else had this problem? I use windows 10 pro 64 bit.  Maheen\n",
            "I don't know for sure, but I would guess that this is because Jaws   17 no longer supports Outlook express, which hasn't been supported   by Microsoft for some time.\n",
            "If JAWS 17 no longer supports Outlook Express, what is the better provider to use? Kevin\n",
            "Hi Kevin:I personally use Outlook 2013 on a laptop and just recently upgraded to Outlook 2016 on my desktop. I am also using Windows 10. Until just recently I was using Windows 8. 1 with outlook 2013. Although some have expressed a dislike for it, I do have clients who use windows live mail with JAWS and seem to like it.   Jeanette McAllister PhD President / CEOAssistive Technology Tutor                 A Heart Staffing                          PO Box 1277Franklin, VA 23851Mobile:757-346-0708www. aheartstaffing. comwww. linkedin. com/in/aheartstaffing Member-National Employment Committee – NFBhttp://employment. nfb. org/                                   Member- Virginia State Rehabilitation Council           Dept for the Blind and Visually Impaired      \"Don't judge each day by the harvest you reap, but by the seeds you plant. \"     --Robert Louis Stevenson                                        ** Note: We respect your Online Privacy. To ensure you receive all future communications please add Jeanette@. . . to your address book. To unsubscribe to future mailings please click on Unsubscribe. We sincerely regret any inconvenience**\n",
            "Well, you could just use Outlook, though that problem (the blanks) occurs in it. I have heard that it might be an Outlook issue. I’m using Windows 10 and MS 2016. Cindy\n",
            "I don't think that JAWS 17 works with Outlook Express. Bye for now, Carolyn\n",
            "I also use Outlook 2013. It has become the devil I know. It would beinteresting to have a chance to see a variety of e-mail clients to seewhich would be more suitable, because there are differences. Bye for now, Carolyn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjqY8pDKyCZJ"
      },
      "source": [
        "from itertools import chain\n",
        "from itertools import product\n",
        "from itertools import starmap\n",
        "from functools import partial\n",
        "import networkx as nx"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvU4f4YwG61-"
      },
      "source": [
        "def get_conversation_dag(tid):\n",
        "  temp = df[df['ThreadID']==tid]\n",
        "\n",
        "  threads = list(temp['Thread'])\n",
        "  postids = list(temp['PostID'])\n",
        "  posts = list(temp['Post'])\n",
        "  datetimes = list(temp['DateTime'])\n",
        "  authors = list(temp['Author'])\n",
        "  parentids = list(temp['ParentID_List'])\n",
        "\n",
        "  G = nx.DiGraph()\n",
        "  G.add_nodes_from(posts)\n",
        "\n",
        "  edges = []\n",
        "  for i in range(len(postids)):\n",
        "    parent = parentids[i]\n",
        "    child = postids[i]\n",
        "\n",
        "    if parent == \"-1\":\n",
        "      continue\n",
        "    else:\n",
        "      parent = int(parent[1:-1])\n",
        "    edges.append((parent,child))\n",
        "  G.add_edges_from(edges)\n",
        "  return G"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q78OSDuQpAB4"
      },
      "source": [
        "def get_subthreads(tid):\n",
        "  temp = df[df['ThreadID']==tid]\n",
        "\n",
        "  threads = list(temp['Thread'])\n",
        "  postids = list(temp['PostID'])\n",
        "  posts = list(temp['Post'])\n",
        "  datetimes = list(temp['DateTime'])\n",
        "  authors = list(temp['Author'])\n",
        "  parentids = list(temp['ParentID_List'])\n",
        "\n",
        "  G = nx.DiGraph()\n",
        "  G.add_nodes_from(posts)\n",
        "\n",
        "  edges = []\n",
        "  for i in range(len(postids)):\n",
        "    parent = parentids[i]\n",
        "    child = postids[i]\n",
        "\n",
        "    if parent == \"-1\":\n",
        "      continue\n",
        "    else:\n",
        "      parent = int(parent[1:-1])\n",
        "    edges.append((parent,child))\n",
        "  G.add_edges_from(edges)\n",
        "  chaini = chain.from_iterable\n",
        "  roots = (n for n,d in G.in_degree() if d==0)\n",
        "  leaves = (n for n,d in G.out_degree() if d==0)\n",
        "  all_paths = partial(nx.all_simple_paths, G)\n",
        "  ans = list(chaini(starmap(all_paths, product(roots, leaves))))\n",
        "  return(ans)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ny0Dg8hjRRA",
        "outputId": "c8463136-d72a-476d-cfe8-e57d67979e3e"
      },
      "source": [
        "get_subthreads(4445)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[21680, 21681], [21680, 21682], [21680, 21683]]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcoRgdChyewT"
      },
      "source": [
        "def get_list_subthreads(threadID):\n",
        "  conversations = []\n",
        "  for i, val in enumerate(get_subthreads(threadID)):\n",
        "    conversations.append(str(i)+\":\"+str(val)[1:-1].replace(',',''))\n",
        "  return conversations"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7auWny7jHMk",
        "outputId": "1b8d95fa-13c2-48d2-af1a-52c2647e90e1"
      },
      "source": [
        "get_list_subthreads(4445)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0:21680 21681', '1:21680 21682', '2:21680 21683']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyTMWsK0DFV8"
      },
      "source": [
        "def read_clusters(filename):\n",
        "    # Read provided data\n",
        "    clusters = {}\n",
        "    cfile = \"\"\n",
        "    all_points = set()\n",
        "    for line in filename:\n",
        "        if ':' in line:\n",
        "            cfile = ':'.join(line.split(':')[:-1]).split('/')[-1]\n",
        "            line = line.split(\":\")[-1]\n",
        "        cluster = {int(v) for v in line.split()}\n",
        "        clusters.setdefault(cfile, []).append(cluster)\n",
        "        for v in cluster:\n",
        "            all_points.add(\"{}:{}\".format(cfile, v))\n",
        "    return clusters, all_points"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPldSHLuFzmM"
      },
      "source": [
        "def create_contingency_table(gold, auto):\n",
        "  table = []\n",
        "  for i, v1 in gold.items():\n",
        "    table_row = []\n",
        "    for j, v2 in auto.items():\n",
        "      table_row.append(len(v1.intersection(v2)))\n",
        "    table.append(table_row)\n",
        "  table = np.array(table)\n",
        "  sum_rows = np.sum(table, axis = 1)\n",
        "  sum_cols = np.sum(table, axis = 0)\n",
        "  return table, sum_rows, sum_cols"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cC43eiCLZFh"
      },
      "source": [
        "gold = {'C1':{0,1,2},'C2':{0,1,3,4},'C3':{0,1,3,5}}"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaNpK3cKLb9C"
      },
      "source": [
        "auto = {'CC1':{0,1,2},'CC2':{0,3,4,5}}"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z_U4CXcFztK"
      },
      "source": [
        "c,rows, cols = create_contingency_table(gold,auto)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-Ro6m88Fz7k",
        "outputId": "ab3bf826-39c9-46b1-d16d-0fa70a7abe85"
      },
      "source": [
        "c"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 1],\n",
              "       [2, 3],\n",
              "       [2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvdiSdDeF0DH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UJN9ZYpIgja"
      },
      "source": [
        "def clusters_to_contingency(gold, auto):\n",
        "    # A table, in the form of:\n",
        "    # https://en.wikipedia.org/wiki/Rand_index#The_contingency_table\n",
        "    table = {}\n",
        "    for filename in auto:\n",
        "        for i, acluster in enumerate(auto[filename]):\n",
        "            aname = \"auto.{}.{}\".format(filename, i)\n",
        "            current = {}\n",
        "            table[aname] = current\n",
        "            for j, gcluster in enumerate(gold[filename]):\n",
        "                gname = \"gold.{}.{}\".format(filename, j)\n",
        "                count = len(acluster.intersection(gcluster))\n",
        "                if count > 0:\n",
        "                    current[gname] = count\n",
        "    counts_a = {}\n",
        "    for filename in auto:\n",
        "        for i, acluster in enumerate(auto[filename]):\n",
        "            aname = \"auto.{}.{}\".format(filename, i)\n",
        "            counts_a[aname] = len(acluster)\n",
        "    counts_g = {}\n",
        "    for filename in gold:\n",
        "        for i, gcluster in enumerate(gold[filename]):\n",
        "            gname = \"gold.{}.{}\".format(filename, i)\n",
        "            counts_g[gname] = len(gcluster)\n",
        "\n",
        "    \n",
        "    return table, counts_a, counts_g"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqXdnof2I2CU"
      },
      "source": [
        "def variation_of_information(contingency, row_sums, col_sums):\n",
        "    total = 0.0\n",
        "    for row in row_sums:\n",
        "        total += row_sums[row]\n",
        "\n",
        "    H_UV = 0.0\n",
        "    I_UV = 0.0\n",
        "    for row in contingency:\n",
        "        for col in contingency[row]:\n",
        "            num = contingency[row][col]\n",
        "            H_UV -= (num / total) * math.log(num / total, 2)\n",
        "            I_UV += (num / total) * math.log(num * total / (row_sums[row] * col_sums[col]), 2)\n",
        "\n",
        "    H_U = 0.0\n",
        "    for row in row_sums:\n",
        "        num = row_sums[row]\n",
        "        H_U -= (num / total) * math.log(num / total, 2)\n",
        "    H_V = 0.0\n",
        "    for col in col_sums:\n",
        "        num = col_sums[col]\n",
        "        H_V -= (num / total) * math.log(num / total, 2)\n",
        "\n",
        "    max_score = math.log(total, 2)\n",
        "    VI = H_UV - I_UV\n",
        "    \n",
        "    scaled_VI = VI / max_score\n",
        "    print(\"{:5.2f}   1 - Scaled VI\".format(1 - scaled_VI))\n",
        "\n",
        "###    # This version will spread values out more, but also introduces a\n",
        "###    # dependence between the prediction and the scale factor, which feels\n",
        "###    # odd (as mentioned in the paper that proposed it).\n",
        "###    normalised_VI = 1 - (I_UV / H_UV)\n",
        "###    print(\"1 - Normalised VI:\", 1 - normalised_VI)\n",
        "\n",
        "###    # http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf\n",
        "###    # Information Theoretic Measures for Clusterings Comparison: Variants,\n",
        "###    # Properties, Normalization and Correction for Chance\n",
        "###    # Vinh, et al. (2010), JMLR\n",
        "###    #\n",
        "###    #   NID = 1 - I(U, V) / max(H(U), H(V))\n",
        "###    #\n",
        "###   normalised_ID = 1 - (I_UV / max(H_U, H_V))\n",
        "###    print(\"1 - Normalised ID:\", 1 - normalised_ID)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-56_-EwZJCBa"
      },
      "source": [
        "def adjusted_rand_index(contingency, row_sums, col_sums, total_elements):\n",
        "    # See https://en.wikipedia.org/wiki/Rand_index\n",
        "    rand_index = 0.0\n",
        "    total = float(total_elements)\n",
        "    print('{:5.2f}   Total Elements'.format(total))\n",
        "    for row in contingency:\n",
        "        for col in contingency[row]:\n",
        "            n = contingency[row][col]\n",
        "            rand_index += n * (n-1) / 2.0\n",
        "    sum_row_choose2 = 0.0\n",
        "    for row in row_sums:\n",
        "        n = row_sums[row]\n",
        "        sum_row_choose2 += n * (n-1) / 2.0\n",
        "    sum_col_choose2 = 0.0\n",
        "    for col in col_sums:\n",
        "        n = col_sums[col]\n",
        "        sum_col_choose2 += n * (n-1) / 2.0\n",
        "    print('{:5.2f}   Sum Row C 2'.format(sum_row_choose2))\n",
        "    print('{:5.2f}   Sum Col C 2'.format(sum_col_choose2))\n",
        "    random_index = (sum_row_choose2 * sum_col_choose2 * 2.0)/(total * (total - 1))\n",
        "    print('{:5.2f}   Random Index'.format(random_index))\n",
        "    max_index = 0.5 * (sum_row_choose2 + sum_col_choose2)\n",
        "    print('{:5.2f}   Max Index'.format(max_index))\n",
        "    adjusted_rand_index = (rand_index - random_index) / (max_index - random_index)\n",
        "\n",
        "    print('{:5.2f}   Adjusted rand index'.format(adjusted_rand_index))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_5dn6jLJH1f"
      },
      "source": [
        "def adjusted_mutual_information(gold, auto):\n",
        "    labels_true = []\n",
        "    order = []\n",
        "    cur = -1\n",
        "    for filename in gold:\n",
        "        for gcluster in gold[filename]:\n",
        "            cur += 1\n",
        "            for num in gcluster:\n",
        "                order.append((filename, num))\n",
        "                labels_true.append(cur)\n",
        "    auto_map = {}\n",
        "    cur = -1\n",
        "    for filename in auto:\n",
        "        for acluster in auto[filename]:\n",
        "            cur += 1\n",
        "            for num in acluster:\n",
        "                auto_map[filename, num] = cur\n",
        "    labels_pred = []\n",
        "    for pair in order:\n",
        "        labels_pred.append(auto_map[pair])\n",
        "\n",
        "    score = metrics.adjusted_mutual_info_score(labels_true, labels_pred, 'max')\n",
        "    print(\"{:5.2f}   adjusted mutual information\".format(score))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J320nLqVJTAU"
      },
      "source": [
        "def shen_f1(contingency, row_sums, col_sums, gold, auto):\n",
        "    total = 0\n",
        "    count = 0\n",
        "    # For each gold cluster, calculate F-score relative to each auto cluster\n",
        "    # and take the max. Then scale those scores by the size of the cluster.\n",
        "    for col in col_sums:\n",
        "        best = 0\n",
        "        best_info = []\n",
        "        col_sum = col_sums[col]\n",
        "        count += col_sum\n",
        "        for row in row_sums:\n",
        "            n = 0\n",
        "            if row in contingency and col in contingency[row]:\n",
        "                n = contingency[row][col]\n",
        "            if n > 0:\n",
        "                row_sum = row_sums[row]\n",
        "                p = n / row_sum\n",
        "                r = n / col_sum\n",
        "                f = 2 * p * r / (p + r)\n",
        "                if f > best:\n",
        "                    best = f\n",
        "                    best_info = [n, row_sum, row]\n",
        "        total += col_sum * best\n",
        "    print(\"{:5.2f}   Shen F1\".format(total / count))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w17mJEMGJeaE"
      },
      "source": [
        "def exact_match(gold, auto, skip_single=True):\n",
        "    # P/R/F over complete clusters\n",
        "    total_gold = 0\n",
        "    total_matched = 0\n",
        "    for filename in gold:\n",
        "        for cluster in gold[filename]:\n",
        "            if skip_single and len(cluster) == 1:\n",
        "                continue\n",
        "            total_gold += 1\n",
        "            matched = False\n",
        "            for ocluster in auto[filename]:\n",
        "                if len(ocluster.symmetric_difference(cluster)) == 0:\n",
        "                    matched = True\n",
        "                    break\n",
        "            if matched:\n",
        "                total_matched += 1\n",
        "    match = []\n",
        "    subsets = []\n",
        "    supersets = []\n",
        "    other = []\n",
        "    prefix = []\n",
        "    suffix = []\n",
        "    gap_free = []\n",
        "    match_counts = []\n",
        "    subsets_counts = []\n",
        "    supersets_counts = []\n",
        "    other_counts = []\n",
        "    prefix_counts = []\n",
        "    suffix_counts = []\n",
        "    gap_free_counts = []\n",
        "    total_auto = 0\n",
        "    for filename in auto:\n",
        "        for cluster in auto[filename]:\n",
        "            if skip_single and len(cluster) == 1:\n",
        "                continue\n",
        "            total_auto += 1\n",
        "            most_overlap = 0\n",
        "            fraction = 0\n",
        "            count = 0\n",
        "            is_subset = False\n",
        "            is_superset = False\n",
        "            is_prefix = False\n",
        "            is_suffix = False\n",
        "            is_gap_free = False\n",
        "            is_match = False\n",
        "            for ocluster in gold[filename]:\n",
        "                if len(ocluster.symmetric_difference(cluster)) == 0:\n",
        "                    is_match = True\n",
        "                    break\n",
        "\n",
        "                overlap = len(ocluster.intersection(cluster))\n",
        "                if overlap > most_overlap:\n",
        "                    most_overlap = overlap\n",
        "                    gaps = False\n",
        "                    for v in ocluster:\n",
        "                        if min(cluster) <= v <= max(cluster):\n",
        "                            if v not in cluster:\n",
        "                                gaps = True\n",
        "                    fraction = 1 - (overlap / len(ocluster.union(cluster)))\n",
        "                    count = len(ocluster.union(cluster)) - overlap\n",
        "\n",
        "                    is_subset = (overlap == len(cluster))\n",
        "                    is_superset = (overlap == len(ocluster))\n",
        "                    if overlap == len(cluster) and (not gaps):\n",
        "                        is_gap_free = True\n",
        "                        if min(ocluster) == min(cluster):\n",
        "                            is_prefix = True\n",
        "                        if max(ocluster) == max(cluster):\n",
        "                            is_suffix = True\n",
        "            if is_match:\n",
        "                match.append(fraction)\n",
        "                match_counts.append(count)\n",
        "            elif is_superset:\n",
        "                supersets.append(fraction)\n",
        "                supersets_counts.append(count)\n",
        "            elif is_subset:\n",
        "                subsets.append(fraction)\n",
        "                subsets_counts.append(count)\n",
        "                if is_prefix:\n",
        "                    prefix.append(fraction)\n",
        "                    prefix_counts.append(count)\n",
        "                elif is_suffix:\n",
        "                    suffix.append(fraction)\n",
        "                    suffix_counts.append(count)\n",
        "                elif is_gap_free:\n",
        "                    gap_free.append(fraction)\n",
        "                    gap_free_counts.append(count)\n",
        "            else:\n",
        "                other.append(fraction)\n",
        "                other_counts.append(count)\n",
        "    print(\"Property, Proportion, Av Frac, Av Count, Max Count, Min Count\")\n",
        "    if len(match) > 0:\n",
        "        print(\"Match        {:5.2f} {:5.2f} {:5.2f}\".format(len(match) / total_auto, sum(match) / len(match), sum(match_counts) / len(match)), max(match_counts), min(match_counts))\n",
        "    if len(supersets) > 0:\n",
        "        print(\"Super        {:5.2f} {:5.2f} {:5.2f}\".format(len(supersets) / total_auto, sum(supersets) / len(supersets), sum(supersets_counts) / len(supersets)), max(supersets_counts), min(supersets_counts))\n",
        "    if len(subsets) > 0:\n",
        "        print(\"Sub          {:5.2f} {:5.2f} {:5.2f}\".format(len(subsets) / total_auto, sum(subsets) / len(subsets), sum(subsets_counts) / len(subsets)), max(subsets_counts), min(subsets_counts))\n",
        "    if len(prefix) > 0:\n",
        "        print(\"Sub-Prefix   {:5.2f} {:5.2f} {:5.2f}\".format(len(prefix) / total_auto, sum(prefix) / len(prefix), sum(prefix_counts) / len(prefix)))\n",
        "    if len(suffix) > 0:\n",
        "        print(\"Sub-Suffix   {:5.2f} {:5.2f} {:5.2f}\".format(len(suffix) / total_auto, sum(suffix) / len(suffix), sum(suffix_counts) / len(suffix)))\n",
        "    if len(gap_free) > 0:\n",
        "        print(\"Sub-GapFree  {:5.2f} {:5.2f} {:5.2f}\".format(len(gap_free) / total_auto, sum(gap_free) / len(gap_free), sum(gap_free_counts) / len(gap_free)))\n",
        "    if len(other) > 0:\n",
        "        print(\"Other        {:5.2f} {:5.2f} {:5.2f}\".format(len(other) / total_auto, sum(other) / len(other), sum(other_counts) / len(other)))\n",
        "\n",
        "    p, r, f = 0.0, 0.0, 0.0\n",
        "    if total_auto > 0:\n",
        "        p = 100 * total_matched / total_auto\n",
        "    if total_gold > 0:\n",
        "        r = 100 * total_matched / total_gold\n",
        "    if total_matched > 0:\n",
        "        f = 2 * p * r / (p + r)\n",
        "    print(\"{:5.2f}   Matched clusters precision\".format(p))\n",
        "    print(\"{:5.2f}   Matched clusters recall\".format(r))\n",
        "    print(\"{:5.2f}   Matched clusters f-score\".format(f))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbNAC4CwJmZv"
      },
      "source": [
        "def numbered_clusters(clusters):\n",
        "    max_cluster = -1\n",
        "    numbered = {}\n",
        "    for cluster in clusters:\n",
        "        max_cluster += 1\n",
        "        for num in cluster:\n",
        "            numbered[num] = max_cluster\n",
        "    return numbered"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjvKuEikJsrM"
      },
      "source": [
        "def elsner_local_error(gold, auto, window=3):\n",
        "    match = 0\n",
        "    total = 0\n",
        "    for filename in auto:\n",
        "        anums = numbered_clusters(auto[filename])\n",
        "        gnums = numbered_clusters(gold[filename])\n",
        "        start = min(min(anums), min(gnums))\n",
        "        end = max(max(anums), max(gnums)) + 1\n",
        "        for num in range(start, end):\n",
        "            if num in anums and num in gnums:\n",
        "                for i in range(-window, 0):\n",
        "                    pos = num + i\n",
        "                    if pos in anums and pos in gnums:\n",
        "                        if (gnums[pos] == gnums[num]) == (anums[pos] == anums[num]):\n",
        "                            match += 1\n",
        "                        total += 1\n",
        "    print(\"{:5.2f}   Local-{}\".format( match / total, window))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX0nPb0eJwRH"
      },
      "source": [
        "def one_to_one(contingency, row_sums, col_sums):\n",
        "    row_to_num = {}\n",
        "    col_to_num = {}\n",
        "    num_to_row = []\n",
        "    num_to_col = []\n",
        "    for row_num, row in enumerate(row_sums):\n",
        "        row_to_num[row] = row_num\n",
        "        num_to_row.append(row)\n",
        "    for col_num, col in enumerate(col_sums):\n",
        "        col_to_num[col] = col_num\n",
        "        num_to_col.append(col)\n",
        "\n",
        "    min_cost_flow = pywrapgraph.SimpleMinCostFlow()\n",
        "    start_nodes = []\n",
        "    end_nodes = []\n",
        "    capacities = []\n",
        "    costs = []\n",
        "    source = len(num_to_row) + len(num_to_col)\n",
        "    sink = len(num_to_row) + len(num_to_col) + 1\n",
        "    supplies = []\n",
        "    tasks = min(len(num_to_row), len(num_to_col))\n",
        "    for row, row_num in row_to_num.items():\n",
        "        start_nodes.append(source)\n",
        "        end_nodes.append(row_num)\n",
        "        capacities.append(1)\n",
        "        costs.append(0)\n",
        "        supplies.append(0)\n",
        "    for col, col_num in col_to_num.items():\n",
        "        start_nodes.append(col_num + len(num_to_row))\n",
        "        end_nodes.append(sink)\n",
        "        capacities.append(1)\n",
        "        costs.append(0)\n",
        "        supplies.append(0)\n",
        "    supplies.append(tasks)\n",
        "    supplies.append(-tasks)\n",
        "    for row, row_num in row_to_num.items():\n",
        "        for col, col_num in col_to_num.items():\n",
        "            cost = 0\n",
        "            if col in contingency[row]:\n",
        "                cost = - contingency[row][col]\n",
        "            start_nodes.append(row_num)\n",
        "            end_nodes.append(col_num + len(num_to_row))\n",
        "            capacities.append(1)\n",
        "            costs.append(cost)\n",
        "\n",
        "    # Add each arc.\n",
        "    for i in range(len(start_nodes)):\n",
        "        min_cost_flow.AddArcWithCapacityAndUnitCost(start_nodes[i], end_nodes[i],\n",
        "                                                    capacities[i], costs[i])\n",
        "  \n",
        "    # Add node supplies.\n",
        "    for i in range(len(supplies)):\n",
        "        min_cost_flow.SetNodeSupply(i, supplies[i])\n",
        "\n",
        "    # Find the minimum cost flow.\n",
        "    min_cost_flow.Solve()\n",
        "\n",
        "    # Score.\n",
        "    total_count = sum(v for _, v in row_sums.items())\n",
        "    overlap = 0\n",
        "    for arc in range(min_cost_flow.NumArcs()):\n",
        "        # Can ignore arcs leading out of source or into sink.\n",
        "        if min_cost_flow.Tail(arc)!=source and min_cost_flow.Head(arc)!=sink:\n",
        "            # Arcs in the solution have a flow value of 1. Their start and end nodes\n",
        "            # give an assignment of worker to task.\n",
        "            if min_cost_flow.Flow(arc) > 0:\n",
        "                row_num = min_cost_flow.Tail(arc)\n",
        "                col_num = min_cost_flow.Head(arc)\n",
        "                col = num_to_col[col_num - len(num_to_row)]\n",
        "                row = num_to_row[row_num]\n",
        "                if col in contingency[row]:\n",
        "                    overlap += contingency[row][col]\n",
        "    print(\"{:5.2f}   one-to-one\".format(overlap / total_count))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfggt39pJ8UH"
      },
      "source": [
        "def correct_start(gold, auto, do_end=False):\n",
        "    # P/R/F for identifying starting messages\n",
        "    gold_starts = set()\n",
        "    for filename in gold:\n",
        "        for cluster in gold[filename]:\n",
        "            start = min(cluster)\n",
        "            if do_end:\n",
        "                start = max(cluster)\n",
        "            gold_starts.add((filename, start))\n",
        "\n",
        "    auto_starts = set()\n",
        "    for filename in auto:\n",
        "        for cluster in auto[filename]:\n",
        "            start = min(cluster)\n",
        "            if do_end:\n",
        "                start = max(cluster)\n",
        "            auto_starts.add((filename, start))\n",
        "\n",
        "    match = len(gold_starts.intersection(auto_starts))\n",
        "\n",
        "    p = 100 * match / len(auto_starts)\n",
        "    r = 100 * match / len(gold_starts)\n",
        "    f = 0.0\n",
        "    if match > 0:\n",
        "        f = 2 * p * r / (p + r)\n",
        "    prefix = \"End\" if do_end else \"Start\"\n",
        "    print(\"{:5.2f}   {} Precision\".format(p, prefix))\n",
        "    print(\"{:5.2f}   {} Recall\".format(r, prefix))\n",
        "    print(\"{:5.2f}   {} F-score\".format(f, prefix))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HztIw8_IKBYa"
      },
      "source": [
        "def start_and_end_together(gold, auto):\n",
        "    # P/R/F for identifying starting messages\n",
        "    total = 0\n",
        "    together = 0\n",
        "    for filename in gold:\n",
        "        for cluster in gold[filename]:\n",
        "            total += 1\n",
        "            start = min(cluster)\n",
        "            end = max(cluster)\n",
        "            found = False\n",
        "            for ocluster in auto[filename]:\n",
        "                if start in ocluster and end in ocluster:\n",
        "                    found = True\n",
        "                    break\n",
        "            if found:\n",
        "                together += 1\n",
        "    print(\"{:5.2f}   Start and end of cluster still together\".format( together / total))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyiXtHvVOQXj",
        "outputId": "6ff70fe8-e833-46ac-837f-9fe94b794ee2"
      },
      "source": [
        "pip install ortools"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ortools in /usr/local/lib/python3.7/dist-packages (9.0.9048)\n",
            "Requirement already satisfied: absl-py>=0.11 in /usr/local/lib/python3.7/dist-packages (from ortools) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.15.8 in /usr/local/lib/python3.7/dist-packages (from ortools) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.11->ortools) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoyxmdteOOXH"
      },
      "source": [
        "import argparse\n",
        "import math\n",
        "import sys\n",
        "\n",
        "from ortools.graph import pywrapgraph\n",
        "from sklearn import metrics"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULZDsMcqY5EO"
      },
      "source": [
        "gt = get_clusters(1)\n",
        "pred = get_clusters(1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwHnA9y1AG3_"
      },
      "source": [
        "gt = ['0:0 1 2',\n",
        " '1:0 1 3 4',\n",
        " '2:0 1 3 5']"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiywQF8DAHEg"
      },
      "source": [
        "pred = ['0:0 1 2 3 4 5']"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_wvbMulKqdq"
      },
      "source": [
        "gold, gpoints = read_clusters(gt)\n",
        "auto, apoints = read_clusters(pred)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ2Hp9lKP-X4",
        "outputId": "3215abdd-540d-435c-e5a3-cb57bd5e7df5"
      },
      "source": [
        "gold"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': [{0, 1, 2}], '1': [{0, 1, 3, 4}], '2': [{0, 1, 3, 5}]}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1QaK-u5P-h-",
        "outputId": "6254eb43-a318-4fad-cadf-4bcfa39c4e81"
      },
      "source": [
        "gpoints"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0:0', '0:1', '0:2', '1:0', '1:1', '1:3', '1:4', '2:0', '2:1', '2:3', '2:5'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sluonFUQDWe",
        "outputId": "d1a564c2-8040-483d-b8a2-ada948a1c193"
      },
      "source": [
        "auto"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': [{0, 1, 2, 3, 4, 5}]}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVcv3XUDQGwu",
        "outputId": "cfe80886-6d9f-4cde-ee8c-d1b547dbcf97"
      },
      "source": [
        "apoints"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0:0', '0:1', '0:2', '0:3', '0:4', '0:5'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e_AAk1HJhho"
      },
      "source": [
        "def get_total_points(gpoints):\n",
        "  points = []\n",
        "  for i in gpoints:\n",
        "    x,y = i.split(':')\n",
        "    points.append(y)\n",
        "  total_points = len(set(points))\n",
        "  return(total_points)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV4QcMCPKAgl",
        "outputId": "d5da873e-0f16-49d7-f9d8-99286654320e"
      },
      "source": [
        "get_total_points(gpoints)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtBz2hHhwzf1"
      },
      "source": [
        "import re, string\n",
        "import sys, os\n",
        "import itertools\n",
        "\n",
        "#############\n",
        "# Calculates the Omega Index as described in Collins and Dent 1988\n",
        "#############\n",
        "def omega_index(gold, auto):\n",
        "  # return dictionary associating objects w/ clusters\n",
        "  def get_post_clusters_dict(data):\n",
        "    val_key_dict = {}\n",
        "    for key,val in data.items():\n",
        "      for i in val[0]:\n",
        "        if i in val_key_dict:\n",
        "          j = val_key_dict.get(i)\n",
        "          val_key_dict[i] = j + [key]\n",
        "        else:\n",
        "          val_key_dict[i] = [key]\n",
        "    for key,val in val_key_dict.items():\n",
        "      val_key_dict[key] = '#'.join(val)\n",
        "    return val_key_dict\n",
        "\n",
        "\n",
        "  # cross-tabulation of # times each pair of objects is clustered together by each solution\n",
        "  # takes two dictionaries associating objects with clusters (two solutions)\n",
        "  # dictionaries have identical keys (objects)\n",
        "  # returns dictionary w/ info on pair clustering for the two solutions\n",
        "  def table(dict1, dict2):\n",
        "\n",
        "      objects = dict1.keys()\n",
        "      pairs = itertools.combinations(objects, 2) # every pair of objects\n",
        "\n",
        "      tabledict = {}\n",
        "\n",
        "      for p in pairs:\n",
        "\n",
        "          sol1w1 = dict1[p[0]]\n",
        "          sol1w2 = dict1[p[1]]\n",
        "          # number of clusters in which pair is together (solution 1)\n",
        "          tog1 = len(set(sol1w1) & set(sol1w2))\n",
        "\n",
        "          sol2w1 = dict2[p[0]]\n",
        "          sol2w2 = dict2[p[1]]\n",
        "          # number of clusters in which pair is together (solution 2)\n",
        "          tog2 = len(set(sol2w1) & set(sol2w2))\n",
        "\n",
        "          #if sol1w1 == ['0'] or sol1w2 == ['0'] or sol2w1 == ['0'] or sol2w2 == ['0']:\n",
        "          #    continue\n",
        "          #else:\n",
        "          tabledict[p] = (tog1, tog2)\n",
        "      return tabledict\n",
        "      \n",
        "  # calculate marginals from the table\n",
        "  # solNumber is the number of the solution (0 or 1)\n",
        "  # returns dictionary of marginals for that solution\n",
        "  def margins(table, solNumber):\n",
        "      tv = table.values()\n",
        "      marginals = {}\n",
        "      d1vals = [e[solNumber] for e in tv]\n",
        "      for k in list(set(d1vals)):\n",
        "          marginals[k] = d1vals.count(k)\n",
        "      return marginals\n",
        "\n",
        "  # uses cross-tabulation to calculate omega index\n",
        "  # returns omega index\n",
        "  def omega(tab):\n",
        "      sol1 = margins(tab, 0)\n",
        "      sol2 = margins(tab, 1)\n",
        "\n",
        "      maxj = min([max(sol1.keys()), max(sol2.keys())])\n",
        "\n",
        "      agree = 0\n",
        "      for pair in tab:\n",
        "          entry = tab[pair]\n",
        "          if entry[0] == entry[1]:\n",
        "              agree += 1\n",
        "      observed = agree * len(tab)\n",
        "      \n",
        "      count = -1\n",
        "      expected = 0\n",
        "      while count < maxj:\n",
        "          count += 1\n",
        "          c1 = sol1[count]\n",
        "          c2 = sol2[count]\n",
        "          expected += (c1 * c2)\n",
        "      num = observed - expected\n",
        "      den = (len(tab)**2) - expected\n",
        "      return float(num) / float(den)\n",
        "\n",
        "  d1 = get_post_clusters_dict(gold)\n",
        "  d2 = get_post_clusters_dict(auto)\n",
        "  tab = table(d1, d2)\n",
        "  score = omega(tab)\n",
        "  return score"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "jooeVlTdKFiY",
        "outputId": "f248b77c-880f-4d19-fda3-842cdf2ab7f2"
      },
      "source": [
        "contingency, row_sums, col_sums = None, None, None\n",
        "contingency, row_sums, col_sums = clusters_to_contingency(gold, auto)\n",
        "print('Variation of Information')\n",
        "variation_of_information(contingency, row_sums, col_sums)\n",
        "print('Shen F1')\n",
        "shen_f1(contingency, row_sums, col_sums, gold, auto)\n",
        "print('Omega Index')\n",
        "omega_index(gold, auto)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variation of Information\n",
            " 0.81   1 - Scaled VI\n",
            "Shen F1\n",
            " 0.18   Shen F1\n",
            "Omega Index\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-4a237d973f1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mshen_f1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontingency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_sums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_sums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Omega Index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0momega_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-1d60159ac3c7>\u001b[0m in \u001b[0;36momega_index\u001b[0;34m(gold, auto)\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_post_clusters_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0mtab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m   \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0momega\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-1d60159ac3c7>\u001b[0m in \u001b[0;36momega\u001b[0;34m(tab)\u001b[0m\n\u001b[1;32m     82\u001b[0m           \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m           \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msol1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m           \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msol2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m           \u001b[0mexpected\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobserved\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJwN2C5V9Ms8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}